---
title: "Effect vs. dummy coding"
author: "Nora Wickelmaier"
date: "2024-11-06"
categories:
  - R
  - Categorical predictors
output:
  md_document:
    variant: gfm
    preserve_yaml: true
---

Let us look at the differences between effect and dummy coding for
regression models with categorical predictors.

# Model with one categorical factor

Let us simulate some data first, for $$n = 10$$ subjects and a group
predictor with levels `ctr` for the control group and `trt` for the
treatment group.

``` r
dat <- data.frame(id    = factor(1:10),
                  group = factor(c("ctr", "trt")),
                  resp  = c(rnorm(5, 1), rnorm(5)))

aggregate(resp ~ group, data = dat, FUN = mean)
```

    ##   group       resp
    ## 1   ctr  0.2609670
    ## 2   trt -0.1312885

Per default are uses so-called dummy coding to represent factors. This
means that the reference category (here `ctr`) is set to 0 and the
second category is set to 1. R takes the first factor level as reference
category in dummy coding.

``` r
contrasts(dat$group)
```

    ##     trt
    ## ctr   0
    ## trt   1

You can check the default settings of your R session with

``` r
options()$contrasts
```

    ##         unordered           ordered 
    ## "contr.treatment"      "contr.poly"

The first entry `"contr.treatment"` indicates dummy coding.

## Linear model with dummy coding

Let us now fit a simple linear regression

$$resp = \beta_0 + \beta_1 group + \varepsilon$$

with $$\varepsilon \sim N(0,\sigma_{\varepsilon})$$.

(For a two-level between factor, this is equivalent to an independent
$$t$$ test.)

``` r
lm1 <- lm(resp ~ group, data = dat)
summary(lm1)
```

    ## 
    ## Call:
    ## lm(formula = resp ~ group, data = dat)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -1.5820 -0.4338 -0.1752  0.6928  1.6374 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)
    ## (Intercept)   0.2610     0.4451   0.586    0.574
    ## grouptrt     -0.3923     0.6295  -0.623    0.551
    ## 
    ## Residual standard error: 0.9953 on 8 degrees of freedom
    ## Multiple R-squared:  0.0463, Adjusted R-squared:  -0.07292 
    ## F-statistic: 0.3883 on 1 and 8 DF,  p-value: 0.5505

``` r
coef(lm1)[1]    # mean ctr
```

    ## (Intercept) 
    ##    0.260967

``` r
sum(coef(lm1))  # mean trt
```

    ## [1] -0.1312885

The interpretation of the parameters is straightforward: The Intercept
$$\beta_0$$ is the mean response in the control (here the reference)
group ($$\bar x_{ctr} = \beta_0$$) and $$\beta_1$$ is the difference
between the control and the treatment group
($$\bar x_{trt} = \beta_0 + \beta_1$$).

## Linear model with effect coding

Next, we will fit the same model with effect coding. Hereby, the
reference group is coded as $$-1$$.

``` r
contrasts(dat$group) <- "contr.sum"
contrasts(dat$group)
```

    ##     [,1]
    ## ctr    1
    ## trt   -1

You can see that for effect coding, R takes the *last* factor level as
reference category.

Now, let us refit the model.

``` r
lm2 <- lm(resp ~ group, dat)
summary(lm2)
```

    ## 
    ## Call:
    ## lm(formula = resp ~ group, data = dat)
    ## 
    ## Residuals:
    ##     Min      1Q  Median      3Q     Max 
    ## -1.5820 -0.4338 -0.1752  0.6928  1.6374 
    ## 
    ## Coefficients:
    ##             Estimate Std. Error t value Pr(>|t|)
    ## (Intercept)  0.06484    0.31473   0.206    0.842
    ## group1       0.19613    0.31473   0.623    0.551
    ## 
    ## Residual standard error: 0.9953 on 8 degrees of freedom
    ## Multiple R-squared:  0.0463, Adjusted R-squared:  -0.07292 
    ## F-statistic: 0.3883 on 1 and 8 DF,  p-value: 0.5505

``` r
sum(coef(lm2))    # mean ctr
```

    ## [1] 0.260967

``` r
-diff(coef(lm2))  # mean trt
```

    ##     group1 
    ## -0.1312885

In this model, the Intercept $$\beta_0$$ is now the overall mean (often
called the grand mean).

``` r
mean(dat$resp)
```

    ## [1] 0.06483924

And $$\beta_1$$ is the difference of the mean in group 1 (here the
control group) to the overall mean and its negative value is the
difference of group 1 (treatment group) to the overall mean.

# Model with two categorical factors

Let us again simulate some data first. This time for $$n = 20$$
subjects, a group predictor like before and an additional factor `study`
with two levels `s1` and `s2`.

``` r
dat <- data.frame(id    = factor(1:20),
                  group = factor(rep(c("ctr", "trt"), each = 10)),
                  study = factor(rep(c("s1", "s2"), each = 5)),
                  resp  = c(rnorm(10, 1), rnorm(10)))

aggregate(resp ~ group + study, data = dat, FUN = mean)
```

    ##   group study       resp
    ## 1   ctr    s1  1.0575195
    ## 2   trt    s1  0.4622200
    ## 3   ctr    s2  1.2211857
    ## 4   trt    s2 -0.2307511

``` r
mean(dat$resp)
```

    ## [1] 0.6275435

``` r
par(mai = c(.8, .8, .1, .1), mgp = c(2.4, 1, 0))
with(dat, interaction.plot(group, study, resp))
```

<img src="https://raw.githubusercontent.com/nwickel/blog/refs/heads/main/figures/2024-11-06_interactionplot-1.png" style="display: block; margin: auto;" />

Both factors are now dummy coded, since we did not tell R to do
otherwise.

``` r
contrasts(dat$group)
```

    ##     trt
    ## ctr   0
    ## trt   1

``` r
contrasts(dat$study)
```

    ##    s2
    ## s1  0
    ## s2  1

## Linear model with dummy coding

Let us now fit regression model with an interaction term

$$resp = \beta_0 + \beta_1 group + \beta_2 study + \beta_3 (group \times
study) + \varepsilon$$

with $$\varepsilon \sim N(0,\sigma_{\varepsilon})$$.

(This is equivalent to a 2x2 ANOVA with two between factors.)

``` r
lm3 <- lm(resp ~ group * study, data = dat)
summary(lm3)
```

    ## 
    ## Call:
    ## lm(formula = resp ~ group * study, data = dat)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1.59696 -0.61529  0.00399  0.56974  1.86454 
    ## 
    ## Coefficients:
    ##                  Estimate Std. Error t value Pr(>|t|)  
    ## (Intercept)        1.0575     0.4582   2.308   0.0347 *
    ## grouptrt          -0.5953     0.6480  -0.919   0.3719  
    ## studys2            0.1637     0.6480   0.253   0.8038  
    ## grouptrt:studys2  -0.8566     0.9165  -0.935   0.3638  
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 1.025 on 16 degrees of freedom
    ## Multiple R-squared:  0.2792, Adjusted R-squared:  0.144 
    ## F-statistic: 2.066 on 3 and 16 DF,  p-value: 0.1452

We can now reconstruct the mean values for all four groups with our
parameters. The Intercept $$\beta_0$$ is now the mean response in study
1 for the control group.

``` r
coef(lm3)[1]
```

    ## (Intercept) 
    ##     1.05752

``` r
coef(lm3)[1] + coef(lm3)[2]
```

    ## (Intercept) 
    ##     0.46222

``` r
coef(lm3)[1] + coef(lm3)[3]
```

    ## (Intercept) 
    ##    1.221186

``` r
coef(lm3)[1] + coef(lm3)[2] + coef(lm3)[3] + coef(lm3)[4]   # sum(coef(lm3))
```

    ## (Intercept) 
    ##  -0.2307511

With dummy coding, we can think of the dummy variables as “controlling”
which parameters are entered into the mean calculations and which are
not. With only categorical predictors, we get a separate equation for
each of the four groups.

$$\begin{align*}
    resp_{11} & = \beta_0 + \varepsilon                      & mean s1 and crt \\
    resp_{12} & = \beta_0 + \beta_1 + \varepsilon            & mean s1 and trt \\
    resp_{21} & = \beta_0 + \beta_2 + \varepsilon            & mean s2 and crt \\
    resp_{22} & = \beta_0 + \beta_1 + \beta_2 + \beta_3 + \varepsilon  & mean s2 und trt
$$\end{align\*}

``` r
colors <- c("lightgray", "darkgray")

datm <- aggregate(resp ~ group + study, data = dat, FUN = mean)

par(mai = c(.8, .8, .1, .1), mgp = c(2.4, 1, 0))
plot(resp ~ jitter(as.numeric(group), .5), data = dat,
     axes = FALSE,
     col = colors[study],
     xlim = c(.7, 2.3),
     xlab = "Group",
     ylab = "Response")
points(resp ~ c(.96, 1.96), data = datm[datm$study == "s1",],
       col = colors[study],
       cex = 3,
       type = "b",
       pch = 16)
points(resp ~ c(1.1, 2.1), data = datm[datm$study == "s2",],
       col = colors[study],
       cex = 3,
       type = "b",
       pch = 16)

axis(1, at = 1:2, labels = c("ctr", "trt"))
axis(2)
box()

legend("topright", c("Study 1", "Study 2"), col = colors, pch = 16, bty = "n", pt.cex = 2)

text(.96,  datm$resp[datm$group == "ctr" & datm$study == "s1"],
     expression(beta[0]))
text(1.96, datm$resp[datm$group == "trt" & datm$study == "s1"],
     expression(beta[0] + beta[1]))
text(1.1,  datm$resp[datm$group == "ctr" & datm$study == "s2"],
     expression(beta[0] + beta[2]))
text(2.1,  datm$resp[datm$group == "trt" & datm$study == "s2"],
     expression(beta[0] + beta[1] + beta[2] + beta[3]))
```

``` r
knitr::include_graphics(paste0("https://raw.githubusercontent.com/nwickel/blog/refs/heads/main/figures/", date, "_dummyplot-1.png"))
```

## Linear model with dummy coding

``` r
contrasts(dat$group) <- "contr.sum"
contrasts(dat$study) <- "contr.sum"

lm4 <- lm(resp ~ group * study, dat)
summary(lm4)
```

    ## 
    ## Call:
    ## lm(formula = resp ~ group * study, data = dat)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1.59696 -0.61529  0.00399  0.56974  1.86454 
    ## 
    ## Coefficients:
    ##               Estimate Std. Error t value Pr(>|t|)  
    ## (Intercept)     0.6275     0.2291   2.739   0.0146 *
    ## group1          0.5118     0.2291   2.234   0.0401 *
    ## study1          0.1323     0.2291   0.578   0.5716  
    ## group1:study1  -0.2142     0.2291  -0.935   0.3638  
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 1.025 on 16 degrees of freedom
    ## Multiple R-squared:  0.2792, Adjusted R-squared:  0.144 
    ## F-statistic: 2.066 on 3 and 16 DF,  p-value: 0.1452

``` r
coef(lm4)[1] + coef(lm4)[2] + coef(lm4)[3] + coef(lm4)[4]
```

    ## (Intercept) 
    ##     1.05752

``` r
coef(lm4)[1] - coef(lm4)[2] + coef(lm4)[3] - coef(lm4)[4]
```

    ## (Intercept) 
    ##     0.46222

``` r
coef(lm4)[1] + coef(lm4)[2] - coef(lm4)[3] - coef(lm4)[4]
```

    ## (Intercept) 
    ##    1.221186

``` r
coef(lm4)[1] - coef(lm4)[2] - coef(lm4)[3] + coef(lm4)[4]   # sum(coef(lm3))
```

    ## (Intercept) 
    ##  -0.2307511

With effects coding, all parameters are needed for calculating each of
the group means. Only the signs change.

$$\begin{align*}
    resp_{11} & = \beta_0 + \beta_1 + \beta_2 + \beta_3 + \varepsilon & mean s1 and crt \\
    resp_{12} & = \beta_0 - \beta_1 + \beta_2 - \beta_3 + \varepsilon & mean s1 and trt \\
    resp_{21} & = \beta_0 + \beta_1 - \beta_2 - \beta_3 + \varepsilon & mean s2 and crt \\
    resp_{22} & = \beta_0 - \beta_1 - \beta_2 + \beta_3 + \varepsilon & mean s2 und trt
$$\end{align\*}

``` r
par(mai = c(.8, .8, .1, .1), mgp = c(2.4, 1, 0))
plot(resp ~ jitter(as.numeric(group), .5), data = dat,
     axes = FALSE,
     col = colors[study],
     xlim = c(.7, 2.3),
     xlab = "Group",
     ylab = "Response")
points(resp ~ c(.96, 1.96), data = datm[datm$study == "s1",],
       col = colors[study],
       cex = 3,
       type = "b",
       pch = 16)
points(resp ~ c(1.1, 2.1), data = datm[datm$study == "s2",],
       col = colors[study],
       cex = 3,
       type = "b",
       pch = 16)
abline(h = mean(dat$resp), lty = 2)

axis(1, at = 1:2, labels = c("ctr", "trt"))
axis(2)
axis(2, at = coef(lm4)[1], labels = expression(beta[0]), las = 2)
box()

arrows(.9, coef(lm4)[1],
       .9, coef(lm4)[1] + coef(lm4)[2],
       length = 0.05,
       col = "#FF6900")
arrows(.93, coef(lm4)[1] + coef(lm4)[2],
       .93, coef(lm4)[1] + coef(lm4)[2] + coef(lm4)[3],
       length = 0.05,
       col = "#91C86E")
arrows(.96, coef(lm4)[1] + coef(lm4)[2] + coef(lm4)[3],
       .96, coef(lm4)[1] + coef(lm4)[2] + coef(lm4)[3] + coef(lm4)[4],
       length = 0.05,
       col = "#3CB4DC")

arrows(1.05, coef(lm4)[1],
       1.05, coef(lm4)[1] + coef(lm4)[2],
       length = 0.05,
       col = "#FF6900")
arrows(1.075, coef(lm4)[1] + coef(lm4)[2],
       1.075, coef(lm4)[1] + coef(lm4)[2] - coef(lm4)[3],
       length = 0.05,
       col = "#91C86E")
arrows(1.1, coef(lm4)[1] + coef(lm4)[2] - coef(lm4)[3],
       1.1, coef(lm4)[1] + coef(lm4)[2] - coef(lm4)[3] - coef(lm4)[4],
       length = 0.05,
       col = "#3CB4DC")

arrows(1.9, coef(lm4)[1],
       1.9, coef(lm4)[1] - coef(lm4)[2],
       length = 0.05,
       col = "#FF6900")
arrows(1.93, coef(lm4)[1] - coef(lm4)[2],
       1.93, coef(lm4)[1] - coef(lm4)[2] + coef(lm4)[3],
       length = 0.05,
       col = "#91C86E")
arrows(1.96, coef(lm4)[1] - coef(lm4)[2] + coef(lm4)[3],
       1.96, coef(lm4)[1] - coef(lm4)[2] + coef(lm4)[3] - coef(lm4)[4],
       length = 0.05,
       col = "#3CB4DC")

arrows(2.05, coef(lm4)[1],
       2.05, coef(lm4)[1] - coef(lm4)[2],
       length = 0.05,
       col = "#FF6900")
arrows(2.075, coef(lm4)[1] - coef(lm4)[2],
       2.075, coef(lm4)[1] - coef(lm4)[2] - coef(lm4)[3],
       length = 0.05,
       col = "#91C86E")
arrows(2.1, coef(lm4)[1] - coef(lm4)[2] - coef(lm4)[3],
       2.1, coef(lm4)[1] - coef(lm4)[2] - coef(lm4)[3] + coef(lm4)[4],
       length = 0.05,
       col = "#3CB4DC")

legend("center",
       c(expression(beta[1]), expression(beta[2]), expression(beta[3])),
       col = c("#FF6900", "#91C86E", "#3CB4DC"), lty = 1, bty = "n")
legend("topright", c("Study 1", "Study 2"), col = colors, pch = 16, bty = "n", pt.cex = 2)
```

``` r
knitr::include_graphics(paste0("https://raw.githubusercontent.com/nwickel/blog/refs/heads/main/figures/", date, "_effectplot-1.png"))
```

# Setting contrasts globally

You can also change the settings for the contrast coding globally in R.

``` r
options(contrasts = c("contr.treatment", "contr.poly"))

options()$contrasts
```

    ## [1] "contr.treatment" "contr.poly"

``` r
contrasts(factor(1:3))
```

    ##   2 3
    ## 1 0 0
    ## 2 1 0
    ## 3 0 1

``` r
options(contrasts = c("contr.sum", "contr.poly"))

options()$contrasts
```

    ## [1] "contr.sum"  "contr.poly"

``` r
contrasts(factor(1:3))
```

    ##   [,1] [,2]
    ## 1    1    0
    ## 2    0    1
    ## 3   -1   -1

# Session info

``` r
sessionInfo()
```

    ## R version 4.4.1 (2024-06-14 ucrt)
    ## Platform: x86_64-w64-mingw32/x64
    ## Running under: Windows 10 x64 (build 19045)
    ## 
    ## Matrix products: default
    ## 
    ## 
    ## locale:
    ## [1] LC_COLLATE=German_Germany.utf8  LC_CTYPE=German_Germany.utf8   
    ## [3] LC_MONETARY=German_Germany.utf8 LC_NUMERIC=C                   
    ## [5] LC_TIME=German_Germany.utf8    
    ## 
    ## time zone: Europe/Berlin
    ## tzcode source: internal
    ## 
    ## attached base packages:
    ## [1] stats     graphics  grDevices utils     datasets  methods   base     
    ## 
    ## loaded via a namespace (and not attached):
    ##  [1] compiler_4.4.1    fastmap_1.2.0     cli_3.6.3         tools_4.4.1      
    ##  [5] htmltools_0.5.8.1 yaml_2.3.10       rmarkdown_2.28    highr_0.11       
    ##  [9] knitr_1.48        xfun_0.48         digest_0.6.37     rlang_1.1.4      
    ## [13] evaluate_1.0.1
